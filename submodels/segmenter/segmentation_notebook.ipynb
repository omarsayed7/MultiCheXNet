{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install git+https://github.com/aleju/imgaug.git","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!git clone https://github.com/ahmadelsallab/MultiCheXNet.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##!rm -r /kaggle/working/MultiCheXNet/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# loss functions and metrics","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\nimport tensorflow.keras.backend as K\nimport tensorflow as tf\nimport numpy as np\ndef get_iou_vector(A, B):\n    # Numpy version\n    B = K.cast(B, 'float32')\n    batch_size = A.shape[0]\n    if batch_size is None:\n      batch_size = 0\n    metric = 0.0\n    for batch in range(batch_size):\n        t, p = A[batch], B[batch]\n        true = np.sum(t)\n        pred = np.sum(p)\n\n        # deal with empty mask first\n        if true == 0:\n            pred_batch_size = pred / ( p.shape[0] * p.shape[1] )\n            if pred_batch_size > 0.03:\n               pred_batch_size = 1 \n            metric +=  1 - pred_batch_size\n            continue\n        \n        # non empty mask case.  Union is never empty \n        # hence it is safe to divide by its number of pixels\n\n        intersection = np.sum(t * p)\n        union = true + pred - intersection\n        iou = intersection / union\n        \n        # iou metrric is a stepwise approximation of the real iou over 0.5\n        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n        \n        metric += iou\n        \n    # teake the average over all images in batch\n    metric /= batch_size\n    return metric\n\n\ndef my_iou_metric(label, pred):\n    # Tensorflow version\n    return tf.py_function(get_iou_vector, [label, pred > 0.5], tf.float64)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.keras.backend as K\ndef dice_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1-dice_coef(y_true, y_pred)\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n\n    intersection = y_true_f * y_pred_f\n    score = (200. * K.sum(intersection) + smooth) / (100. * K.sum(y_true_f) + 100.* K.sum(y_pred_f) + smooth)\n    return  (1. - score)\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n\ndef bce_logdice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\ndef binary_focal_loss(gamma=2., alpha=.25):\n    \"\"\"\n    Binary form of focal loss.\n      FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n      where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n    References:\n        https://arxiv.org/pdf/1708.02002.pdf\n    Usage:\n     model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n    \"\"\"\n    def binary_focal_loss_fixed(y_true, y_pred):\n        \"\"\"\n        :param y_true: A tensor of the same shape as `y_pred`\n        :param y_pred:  A tensor resulting from a sigmoid\n        :return: Output tensor.\n        \"\"\"\n        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n\n        epsilon = K.epsilon()\n        # clip to prevent NaN's and Inf's\n        pt_1 = K.clip(pt_1, epsilon, 1. - epsilon)\n        pt_0 = K.clip(pt_0, epsilon, 1. - epsilon)\n\n        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) \\\n               -K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n\n    return binary_focal_loss_fixed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def jaccard_distance_loss(y_true, y_pred, smooth=100):\n    \"\"\"\n    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n    \n    The jaccard distance loss is usefull for unbalanced datasets. This has been\n    shifted so it converges on 0 and is smoothed to avoid exploding or disapearing\n    gradient.\n    \n    Ref: https://en.wikipedia.org/wiki/Jaccard_index\n    \n    @url: https://gist.github.com/wassname/f1452b748efcbeb4cb9b1d059dce6f96\n    @author: wassname\n    \"\"\"\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return (1 - jac) * smooth","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Segmentation Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from MultiCheXNet.data_loader.SIIM_ACR_dataloader import get_train_validation_generator\nfrom MultiCheXNet.MTL_model import MTL_model\nfrom tensorflow.keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seg_csv_path = \"/kaggle/input/siim-acr-pneumothorax-segmentation-data/train-rle.csv\"\nseg_images_path = \"/kaggle/input/siim-acr-pneumothorax-segmentation-data/dicom-images-train/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen,val_gen = get_train_validation_generator(seg_csv_path , seg_images_path, only_positive=False, augmentation=True,hist_eq=True,batch_positive_portion=0.5 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X,Y = next(enumerate(train_gen))[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nfor yy in Y:\n    plt.imshow(np.squeeze(yy))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MTL_model_clss = MTL_model(add_class_head=False,add_detector_head=False,add_segmenter_head=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = MTL_model_clss.MTL_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr=1e-4\nepochs=10\nmodel.compile(loss= binary_focal_loss(), optimizer=Adam(lr) , metrics=[ dice_coef , my_iou_metric])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist= model.fit_generator(train_gen, validation_data=val_gen, epochs=epochs,class_weight={0:1,1:100} )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#0.1\n#0.978\n#0.77","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#0.04\n#0.93\n#0.01","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# segmentation training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import *\ndef dense_block(x, blocks, name):\n    #REF: keras-team\n    \"\"\"A dense block.\n    # Arguments\n        x: input tensor.\n        blocks: integer, the number of building blocks.\n        name: string, block label.\n    # Returns\n        output tensor for the block.\n    \"\"\"\n    for i in range(blocks):\n        x = conv_block(x, 32, name=name + '_block' + str(i + 1))\n    return x\ndef conv_block(x, growth_rate, name):\n    #REF: keras-team\n    \"\"\"A building block for a dense block.\n    # Arguments\n        x: input tensor.\n        growth_rate: float, growth rate at dense layers.\n        name: string, block label.\n    # Returns\n        Output tensor for the block.\n    \"\"\"\n    bn_axis = 3\n    x1 = BatchNormalization(axis=bn_axis,\n                                   epsilon=1.001e-5,\n                                   name=name + '_0_bn')(x)\n    x1 = Activation('relu', name=name + '_0_relu')(x1)\n    x1 = Conv2D(4 * growth_rate, 1,\n                       use_bias=False,\n                       name=name + '_1_conv')(x1)\n    x1 = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                                   name=name + '_1_bn')(x1)\n    x1 = Activation('relu', name=name + '_1_relu')(x1)\n    x1 = Conv2D(growth_rate, 3,\n                       padding='same',\n                       use_bias=False,\n                       name=name + '_2_conv')(x1)\n    x = Concatenate(axis=bn_axis, name=name + '_concat')([x, x1])\n    return x\n\ndef transition_up(x, encoder, skip_connection, out_channels, kernel_size=(3,3), stride=(2,2)):\n    tu = Conv2DTranspose(out_channels, kernel_size, strides = stride, padding = 'same')(x)\n    skip = encoder.layers[skip_connection].output\n    c = concatenate([skip,tu], axis=3)\n    return c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from MultiCheXNet.utils.Encoder import Encoder\nfrom MultiCheXNet.utils.ModelBlock import ModelBlock\nfrom MultiCheXNet.utils.Segmenter import Segmenter ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_class = Encoder(weights=None)\nseg_head= Segmenter(encoder_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ModelBlock.add_heads(encoder_class ,[seg_head] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\nfrom keras import backend as K\ndef get_iou_vector(A, B):\n    # Numpy version\n    B = K.cast(B, 'float32')\n    batch_size = A.shape[0]\n    if batch_size is None:\n      batch_size = 0\n    metric = 0.0\n    for batch in range(batch_size):\n        t, p = A[batch], B[batch]\n        true = np.sum(t)\n        pred = np.sum(p)\n\n        # deal with empty mask first\n        if true == 0:\n            pred_batch_size = pred / ( p.shape[0] * p.shape[1] )\n            if pred_batch_size > 0.03:\n               pred_batch_size = 1 \n            metric +=  1 - pred_batch_size\n            continue\n        \n        # non empty mask case.  Union is never empty \n        # hence it is safe to divide by its number of pixels\n\n        intersection = np.sum(t * p)\n        union = true + pred - intersection\n        iou = intersection / union\n        \n        # iou metrric is a stepwise approximation of the real iou over 0.5\n        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n        \n        metric += iou\n        \n    # teake the average over all images in batch\n    metric /= batch_size\n    return metric\n\n\ndef my_iou_metric(label, pred):\n    # Tensorflow version\n    return tf.py_function(get_iou_vector, [label, pred > 0.5], tf.float64)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred = K.cast(y_pred, 'float32')\n    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n    intersection = y_true_f * y_pred_f\n    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n    return 100 * score\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from MultiCheXNet.data_loader.SIIM_ACR_dataloader import get_train_validation_generator\nseg_csv_path = \"/kaggle/input/siim-acr-pneumothorax-segmentation-data/train-rle.csv\"\nseg_images_path = \"/kaggle/input/siim-acr-pneumothorax-segmentation-data/dicom-images-train/\"\n\nseg_train_gen , seg_val_gen = get_train_validation_generator(seg_csv_path,seg_images_path ,augmentation=True,hist_eq=True,normalize=True )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.optimizers import Adam\nmodel.compile(loss= \"binary_crossentropy\", optimizer=Adam(1e-4), metrics=[dice_coef,my_iou_metric])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(seg_train_gen,validation_data=seg_val_gen , epochs=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skip_layers = [308,136,48]\nblocks = [3, 3, 3, 3]\n\ndb5 = encoder.output #(8,8,1024)\ntu5 = transition_up(db5, encoder, skip_layers[0], 3)\n\ndb6 = dense_block(tu5, blocks[-1], name='conv6')\ntu6 = transition_up(db6, encoder, skip_layers[1], 3)\n\ndb7 = dense_block(tu6, blocks[-2], name='conv7')\ntu7 = transition_up(db7, encoder, skip_layers[2], 3)\n\ndb8 = dense_block(tu7, blocks[-3], name='conv8')\ntu8 = Conv2DTranspose(256, (3, 3), strides = (2, 2), padding = 'same')(db8)#(128,128,)\n\nuconv9 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same')(tu8)\ntu9 = Conv2DTranspose(256, (3, 3), strides = (2, 2), padding = 'same')(uconv9)#(256,256,)\noutputs = Conv2D(1, (1, 1), activation = 'sigmoid')(tu9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred = K.cast(y_pred, 'float32')\n    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n    intersection = y_true_f * y_pred_f\n    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n    return 100 * score\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n\n    intersection = y_true_f * y_pred_f\n    score = (200. * K.sum(intersection) + smooth) / (100. * K.sum(y_true_f) + 100.* K.sum(y_pred_f) + smooth)\n    return  (1. - score)\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n\ndef bce_logdice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from MultiCheXNet.data_loader.SIIM_ACR_dataloader import get_train_validation_generator\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seg_csv_path = \"/kaggle/input/siim-acr-pneumothorax-segmentation-data/train-rle.csv\"\nseg_images_path = \"/kaggle/input/siim-acr-pneumothorax-segmentation-data/dicom-images-train/\"\n\nseg_train_gen , seg_val_gen = get_train_validation_generator(seg_csv_path,seg_images_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X,y = next(enumerate(seg_val_gen))[1]\nX.shape,y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nmodel.compile(loss= dice_loss, optimizer=Adam(1e-4), metrics=[dice_coef,my_iou_metric ])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\n\nmodel.fit_generator(seg_train_gen , validation_data=seg_val_gen , epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seg_csv_path = \"/kaggle/input/siim-acr-pneumothorax-segmentation-data/train-rle.csv\"\nseg_images_path = \"/kaggle/input/siim-acr-pneumothorax-segmentation-data/dicom-images-train/\"\n\nseg_train_gen , seg_val_gen = get_train_validation_generator(seg_csv_path,seg_images_path ,augmentation=True,hist_eq=True,normalize=True )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Second try","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from MultiCheXNet.utils.Encoder import Encoder\nfrom MultiCheXNet.utils.ModelBlock import ModelBlock","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_class = Encoder(weights=None)\nencoder = encoder_class.model ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Conv2DTranspose, Conv2D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = Conv2DTranspose(512, (3, 3), strides = (2, 2), padding = 'same',activation='relu')(encoder.output)#(16,16,)\nX = Conv2D(512 , (1,1), padding='same',activation='relu')(X)\nX = Conv2D(512 , (1,1), padding='same',activation='relu')(X)\n\n\nX = Conv2DTranspose(256, (3, 3), strides = (2, 2), padding = 'same',activation='relu')(X)#(32,32,)\nX = Conv2D(256 , (1,1), padding='same',activation='relu')(X)\nX = Conv2D(256 , (1,1), padding='same',activation='relu')(X)\n\nX = Conv2DTranspose(128, (3, 3), strides = (2, 2), padding = 'same',activation='relu')(X)#(64,64,)\nX = Conv2D(128 , (1,1), padding='same',activation='relu')(X)\nX = Conv2D(128 , (1,1), padding='same',activation='relu')(X)\n\nX = Conv2DTranspose(128, (3, 3), strides = (2, 2), padding = 'same',activation='relu')(X)#(128,128,)\nX = Conv2D(128 , (1,1), padding='same',activation='relu')(X)\nX = Conv2D(128 , (1,1), padding='same',activation='relu')(X)\n\nX = Conv2DTranspose(64, (3, 3), strides = (2, 2), padding = 'same',activation='relu')(X)#(256,256,)\nX = Conv2D(32 , (1,1), padding='same',activation='relu')(X)\nX = Conv2D(32 , (1,1), padding='same',activation='relu')(X)\nX = Conv2D(1 , (1,1), padding='same',activation='sigmoid')(X)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model= ModelBlock.add_heads(encoder_class, [X] ,is_classes=False )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.densenet import preprocess_input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from MultiCheXNet.data_loader.SIIM_ACR_dataloader import get_train_validation_generator\nseg_csv_path = \"/kaggle/input/siim-acr-pneumothorax-segmentation-data/train-rle.csv\"\nseg_images_path = \"/kaggle/input/siim-acr-pneumothorax-segmentation-data/dicom-images-train/\"\n\nseg_train_gen , seg_val_gen = get_train_validation_generator(seg_csv_path,seg_images_path ,augmentation=True,hist_eq=True,normalize=True  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nimport tensorflow as tf\nimport numpy as np\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss= \"binary_crossentropy\", optimizer=Adam(1e-5), metrics=[dice_coef,my_iou_metric ])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(seg_train_gen , validation_data=seg_val_gen , epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}